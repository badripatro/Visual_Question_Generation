{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "test = json.load(open('cocofinal_attention_val.json', 'r'))\n",
    "train = json.load(open('cocofinal_attention_train.json', 'r'))\n",
    "# print len(test)\n",
    "# print len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'img_id': 519601, u'ques_cap_id': 51960111, u'question': u'Is this train still operating today?', u'caption': u'A train traveling down tracks near a tree filled forest.', u'ques_id': 5196011, u'file_path': u'train2014/COCO_train2014_000000519601.jpg'}\n",
      "{u'img_id': 314392, u'ques_cap_id': 31439211, u'question': u'What is she drinking?', u'caption': u'A woman standing in a room holding a cup', u'ques_id': 3143921, u'file_path': u'train2014/COCO_train2014_000000314392.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print test[0]\n",
    "print train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from random import shuffle, seed\n",
    "import sys\n",
    "import os.path\n",
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import scipy.io\n",
    "import pdb\n",
    "import string\n",
    "import h5py\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "def posfinder(caption):\n",
    "    wordDict = {}\n",
    "    tagDict = {}\n",
    "    tagNSet = set()# noun Set #http://www.computational-logic.org/iccl/master/lectures/summer06/nlp/part-of-speech-tagging.pdf\n",
    "    tagVSet = set()#verb set\n",
    "    tagWSet = set()#verb set\n",
    "    tagPSet = set()#pronoun set\n",
    "    tagAdSet = set()#Adjective set\n",
    "    tagAvSet = set()#Adverb set\n",
    "    tagOSet = set()#other set\n",
    "\n",
    "    # sentence = \"Hello my name is Abhishek Mitra\"\n",
    "    sentence = caption\n",
    "    sentence = word_tokenize(sentence)\n",
    "    posTags = nltk.pos_tag(sentence)\n",
    "#     print('sent',posTags)\n",
    "\n",
    "#     print [s for s in posTags if s[1] != 'NN' and s[1] != 'NNP']\n",
    "\n",
    "    for s in posTags:\n",
    "        if s[1].startswith('NN') or s[1].startswith('NNS') or s[1].startswith('NNP') or s[1].startswith('NNPS'): # for noun\n",
    "            tagNSet.add(s[0])\n",
    "        elif s[1].startswith('VB') or s[1].startswith('VBG') or s[1].startswith('VBN') or s[1].startswith('VBP') or s[1].startswith('VBZ') or s[1].startswith('VBD'): #for verb\n",
    "            tagVSet.add(s[0])\n",
    "        elif s[1].startswith('WDT') or s[1].startswith('WP') or s[1].startswith('WP$') or s[1].startswith('WRB'): # wh words\n",
    "            tagWSet.add(s[0])\n",
    "        elif s[1].startswith('PP') or s[1].startswith('PP$') : # pronoun words\n",
    "            tagPSet.add(s[0])\n",
    "        elif s[1].startswith('RB') or s[1].startswith('RBR') or s[1].startswith('RBS') : # adverb words\n",
    "            tagAvSet.add(s[0])\n",
    "        elif s[1].startswith('JJ') or s[1].startswith('JJR') or s[1].startswith('JJS'): # Adjective words\n",
    "            tagAdSet.add(s[0])\n",
    "        else:    \n",
    "            tagOSet.add(s[0])\n",
    "    Nset = list(tagNSet|tagPSet|tagAdSet)\n",
    "    Vset = list(tagVSet)\n",
    "    Whset = list(tagWSet)\n",
    "    count = 0\n",
    "    noun = ''\n",
    "    if len(Nset)==0:\n",
    "        noun = \" \"\n",
    "    else:\n",
    "        while(count<5):\n",
    "            for j in range(len(Nset)):\n",
    "                noun = noun + ' ' + Nset[j]\n",
    "                count += 1\n",
    "                if count == 5:\n",
    "                    break\n",
    "    # print count\n",
    "#         for j in range(len(Nset)):\n",
    "#             if count == 5:\n",
    "#                 break\n",
    "#             noun = noun + ' ' + Nset[j]\n",
    "#             count += 1    \n",
    "    count = 0\n",
    "    verb = ''\n",
    "    if len(Vset)==0:\n",
    "        verb = \" \"\n",
    "    else:\n",
    "        while(count<5):\n",
    "            for j in range(len(Vset)):\n",
    "                verb = verb + ' ' + Vset[j]\n",
    "                count += 1\n",
    "                if count == 5:\n",
    "                    break\n",
    "#     # print count\n",
    "#         for j in range(len(Vset)):\n",
    "#             if count == 5:\n",
    "#                 break\n",
    "#             verb = verb + ' ' + Vset[j]\n",
    "#             count += 1\n",
    "            \n",
    "    count = 0\n",
    "    whword = ''\n",
    "    if len(Whset)==0:\n",
    "        whword = \" \"\n",
    "    else:\n",
    "        while(count<5):\n",
    "            for j in range(len(Whset)):\n",
    "                whword = whword + ' ' + Whset[j]\n",
    "                count += 1\n",
    "\n",
    "#             if count == 5:\n",
    "#                 break\n",
    "    # print count\n",
    "#         for j in range(len(Whset)):\n",
    "#             if count == 5:\n",
    "#                 break\n",
    "#             whword = whword + ' ' + Whset[j]\n",
    "#             count += 1\n",
    "\n",
    "    \n",
    "    return noun,verb,whword\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman standing in a room holding a cu What is she drinking?\n",
      "(u' woman room cu woman room', u' standing is drinking holding standing', u' What What What What What')\n",
      " woman room cu woman room\n",
      "why how when what who which where \n"
     ]
    }
   ],
   "source": [
    "print train[0]['caption'][:-1] + ' ' + train[0]['question']\n",
    "x = posfinder(train[0]['caption'][:-1] + ' ' + train[0]['question'])\n",
    "print x\n",
    "print x[0]\n",
    "wh = 'why how when what who which where '.decode('utf-8')\n",
    "\n",
    "print wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /users/gpu/badri1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "62500\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "img=train\n",
    "# outermost = {}\n",
    "out = [] #len(raw_img)\n",
    "for i in range(0,len(img)):#len(img)\n",
    "    \n",
    "    imgid = img[i]['img_id']\n",
    "    qcapid = img[i]['ques_cap_id']\n",
    "    quesid = img[i]['ques_id']\n",
    "    ques = img[i]['question']\n",
    "    imgpath = img[i]['file_path']\n",
    "    capt = img[i]['caption']\n",
    "    noun,verb,whword = posfinder(capt[:-1] + ' ' + ques)\n",
    "    #     ans = raw_img[i]['ans']\n",
    "    \n",
    "    \n",
    "#     for j in range(0,len(img)):\n",
    "#         if img[j]['file_name'] == imgpath:\n",
    "#             capt = img[j]['caption']\n",
    "    #ques = imgs[i]['questions'].split(u'---')\n",
    "    #final_imgid = \"COCO_img2014_{0:012d}.jpg\".format(imgid)\n",
    "    #print capt\n",
    "    #loc = 'sab'\n",
    "    #loc = 'img2014/'\n",
    "\n",
    "    jimg = {}\n",
    "    jimg['caption'] = capt\n",
    "    jimg['question'] = ques\n",
    "    jimg['img_path'] = imgpath\n",
    "    jimg['ques_id'] =  quesid\n",
    "    jimg['ques_cap_id'] =  qcapid\n",
    "    jimg['image_id'] =  imgid\n",
    "    jimg['noun'] = noun\n",
    "    jimg['verb'] = verb\n",
    "    jimg['whword'] = wh\n",
    "    #     jimg['ans'] = ans\n",
    "    #sent= []\n",
    "    #sent.append(ques)\n",
    "    out.append(jimg)\n",
    "#out.append('}')\n",
    "#print capt\n",
    "# outermost['questions'] = out\n",
    "print (len(out))\n",
    "json.dump(out, open('coco_pos_tv_train.json', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' pink box eyes woman purse', ' standing use standing use standing', ' Why Why Why Why Why')\n",
      "{'noun': u' woman door room cup woman', 'img_path': u'train2014/COCO_train2014_000000314392.jpg', 'caption': u'A woman in a room holding a cup and a door behind her', 'ques_cap_id': 31439212, 'question': u'What is she drinking?', 'whword': u'why how when what who which where ', 'image_id': 314392, 'verb': u' is drinking holding is drinking', 'ques_id': 3143921}\n"
     ]
    }
   ],
   "source": [
    "print posfinder('A woman standing next to a pink box with eyes Why you use that purse')\n",
    "print out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
